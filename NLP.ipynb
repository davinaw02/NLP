{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1y4o4qIHM-iFd4LjJQjCNovcvZ24FZgzX",
      "authorship_tag": "ABX9TyNV/RkdRu99oUS0pSFlJeXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davinaw02/NLP/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative AI was used to support completion of this assessment. The gen AI tool gemmi on google colab was used in the process of code error checking and resolution and spelling"
      ],
      "metadata": {
        "id": "0sImhm8YA6dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "vx10E-X5hPNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dataset"
      ],
      "metadata": {
        "id": "5yhrcf0ohUOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "folder = snapshot_download(\n",
        "                \"HuggingFaceFW/finewiki\",\n",
        "                repo_type=\"dataset\",\n",
        "                local_dir=\"./finewiki/\",\n",
        "                allow_patterns=[\"data/enwiki/*\"])\n"
      ],
      "metadata": {
        "id": "y97Qehzu-WVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "fw = load_dataset(\"HuggingFaceFW/finewiki\", name=\"en\", split=\"train\", streaming=True)"
      ],
      "metadata": {
        "id": "vjEjpQvN-i4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section 1\n",
        "Natutral Language Processing (NLP) allows computers to automatically understand and analyse a huge amount of text. One area this can be particulary effective is helping classify and organise huge online encycloaedic sources such as wikipedia. This project uses the FineWiki dataset from Hugging Face, a huge collection of cleaned wikipedia articles, each including metadata and text including a label called has_math which identifies whether the article contains any mathematical content.\n",
        "The goal of the project is to build and compare two text classification piplines that predict whether an article is mathematical or not. automating the process can support for topic filtering, indexing aand archiving where mathematical content need to be identified.\n",
        "the assigment compares two MLP approaches that use the same feature representation (TF-IDF) but different machine learning algorithms, Logistic Regression and Support Vector Machines (SVMs). these models represent classic methods that perform well on sparse text data and allow interpretable or robust classification. By evaluating both models on the same dataset this project aims to identify which technique offers for better generalisation, accuracy and suitability for the task of mathematical context detection."
      ],
      "metadata": {
        "id": "_zzmP3vCQEzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report"
      ],
      "metadata": {
        "id": "KZ9YufuA__EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(fw.take(1000)))\n",
        "\n",
        "df['has_math'] = df['text'].apply(lambda x: bool(re.search(r'\\$.*\\$', x) if isinstance(x, str) else False))\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df['text'], df['has_math'], test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "Kx4ltcZMWslm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section 2\n",
        "Machine-learning models cannot process raw text directly so the text must be converted into numerical form. This process is know as representation learning. In this project a single representation learning approach is used: Term Frequency-Inverse Document Frequency (TF-IDF).\n",
        "TF-IDF is a widely used method in classic NLP. It works by counting how often each word appears in a document and adjusting that score by how common the word is across thw whole dataset. Rare but informative words receive higher weights, while common words such as ‘and’ and ‘the’ would receive lower weights\n",
        "It is especially suitable for the dataset because mathematical articles contain specific terminology. The distinctive words help the model separate mathematical articles from the non-mathematical ones. the TF-IDF method converts each article into a long vector containing thousands of numbers, each representing the importance of a specific word.\n",
        "The representation is understandable, efficient and works very well with the classical algorithms such as logistic regression and SVMs because of the simplicity and effectiveness. TF-IDF is widely used as a baseline text representation technique in many NLP research studies."
      ],
      "metadata": {
        "id": "BXZSL84-WDnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "x_train = vectorizer.fit_transform(train_texts)\n",
        "x_test = vectorizer.transform(test_texts)"
      ],
      "metadata": {
        "id": "zN3sahZnX0E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section 3\n",
        "The project compares two classical machine learning algorithms, logistic regression and SVMs. Both of which are well established in NLP and work effectively with TF-IDF text representations. Although they use the same input features the algorithms operate differently, allowing a meaningful comparison of model performance and behaviour.\n",
        "1.\tLogistic Regression\n",
        "This is a linear classification algorithm that predicts a probability between 0 and 1 using the logistic function. It assumes that classes can be separated by a straight line in feature space. In text classification each TF-IDF value represents the importance oof a word and the logistic regression learns which words push the prediction toward math or no math.\n",
        "An advantage of this is interpretability. The models learned weights ca be inspected directly to see which words contribute most to each class. It is also easy to train, is a widely used in NLP research as a baseline classifier and it can handle huge sparse datasets well.\n",
        "2.\tSVM\n",
        "These powerful classifiers that attempt to maximise the margin between classes. rather than predicting the probabilities SVMs focus on finding the best possible decision boundary between mathematical and non mathematical articles. SVMs are very effective wit TF-IDF features because text data is high dimensional and sparse.\n",
        "An advantage is these are known to be strong in performance for many text classification benchmarks. They are tough to noisy features and can often outperform logistic regression when classes overlap.\n"
      ],
      "metadata": {
        "id": "EiJam1UuYnDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(x_train, train_labels)\n",
        "\n",
        "lr_predictions = lr_model.predict(x_test)"
      ],
      "metadata": {
        "id": "sRDRVU4KYIjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = LinearSVC()\n",
        "svm_model.fit(x_train, train_labels)\n",
        "\n",
        "svm_predictions = svm_model.predict(x_test)"
      ],
      "metadata": {
        "id": "yk1xh3dHYs0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logistic Regression Results:\")\n",
        "print(\"Accuracy\",accuracy_score(test_labels, lr_predictions))\n",
        "print(\"Precision\",precision_score(test_labels, lr_predictions))\n",
        "print(classification_report(test_labels, lr_predictions))\n",
        "\n",
        "print(\"\\nSVM Results:\")\n",
        "print(\"Accuracy\",accuracy_score(test_labels, svm_predictions))\n",
        "print(classification_report(test_labels, svm_predictions))"
      ],
      "metadata": {
        "id": "kpVY827XY-uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section 4\n",
        "Both models were evaluated using the same dataset split, ensuring fair comparison. It uses accuracy and classification report which includes precision, recall and F1 score. These metrics show how each model identifies mathematical and non mathematical articles.\n",
        "Logistic regression tends to perform well when distinctive words strongly correlate with a class, making it suitable for this dataset. SVMs typically perform better on high dimensional TF-IDF vectors, offering stronger generalisation.\n",
        "A confusion matrix may also be used to examine how frequently each model misclassifies articles, revealing whether models struggle with borderline cases.\n",
        "In addition to overall performance model simplicity and training time were considered. Logistic regression trains very quickly and provides transparency, while SVMs may take slight longer but produce stronger decision boundaries. Evaluating both models helps identify the balance between interpretability, accuracy and speed. This evaluation allows for a clear understanding of which classical NLP approach performs best for detecting mathematical content in the dataset\n"
      ],
      "metadata": {
        "id": "22FBbiZNZ9xQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "section 5 and 6\n",
        "the paper introduces a family of machine learning methods that rely entirely on strong and comparing specific instances rather than building abstract models. The algorithms belong to the broader class of nearest neighbour methods, where new examples are classified based on their similarity to previous seen examples. The paper analyses the fundamental IB1, IB2 and IB3 algorithms and investigates how strong, selecting and updating instances affects model accuracy, generality and noise tolerance.\n",
        "The authors demonstrate that the basic IB1 algorithm is effective but computationally expensive because it stores all examples. IB2 addresses this by strong only misclassified instances, reducing storage but increasing vulnerability to noisy data. The final algorithm, IB3 introduces a statistical filtering mechanism that evaluates how reliable each stored instance is based on its historical performance, making it more strong to noise and more efficient than previous versions.\n",
        "The papers main contribution is its framework for understanding instance based learning as a principled method rather a simple nearest neighbour investigative. It provides rigorous theoretical analysis, explains behaviour under noise, introduces significance testing.\n"
      ],
      "metadata": {
        "id": "NI-OLbn7aQOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class NearestNeighborsClassifier:\n",
        "  def __init__(self):\n",
        "    self.X_train = None\n",
        "    self.y_train = None\n",
        "\n",
        "  def fit (self, X, y):\n",
        "    self.X_train = X\n",
        "    self.y_train = y\n",
        "\n",
        "  def predict(self, X):\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(X.shape[0]):\n",
        "      sims = cosine_similarity(X[i], self.X_train)[0]\n",
        "      nearest = np.argmax(sims)\n",
        "      predictions.append(self.y_train.iloc[nearest])\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "-9X1XhfUaekc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ib1 = NearestNeighborsClassifier()\n",
        "ib1.fit(x_train, train_labels)\n",
        "\n",
        "ib1_predictions = ib1.predict(x_test)\n",
        "\n",
        "print(\"IB1 Results:\", accuracy_score(test_labels, ib1_predictions))\n",
        "print(classification_report(test_labels, ib1_predictions))"
      ],
      "metadata": {
        "id": "hh5y_3WGkbHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "section 7\n",
        "To reproduce the experiment the IB1 instance based learning algorithm was implemented and evaluated on the FineWiki dataset using the TF-IDF representation as in the two main pipelines. The authors report that it usually achieves strong accuracy on clean, noise free datasets but suffers from high storage cost and slow classification time. The results confirm this.\n",
        "Compared with the logistic regression and SVM, the IB1 classifier showed a lower accuracy, possibly because nearest neighbour methods are sensitive to high dimensionality which reduces the effectiveness of cosine similarity when the number of features is really huge. Additionally in the paper IB1 performs well on structured numeric datasets, whereas the wikipedia texts include a large variation of vocabulary and inconsistent text, weaking local similarity signals.\n",
        "Despite lower accuracy IB1 behaved cosistently with the papers predictions.\n",
        "It stored all training examples, classification was slighlty slower than LR/SVM, its errors were most common on vague or borderline texts matching the papers theoretical analysis and it showed no toughness against noise and irrelevant features, also consistent with the findings of the authors.\n",
        "overall the reproduction supports the papers conclusions that instance based learning is simple and interpretable but less efficent and less accurate on noisy, high dimensional text data"
      ],
      "metadata": {
        "id": "Inj7sDtrafXx"
      }
    }
  ]
}